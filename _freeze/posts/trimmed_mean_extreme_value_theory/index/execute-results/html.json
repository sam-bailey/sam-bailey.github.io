{
  "hash": "a2dfe47ed674bd48969a35ea471fc625",
  "result": {
    "markdown": "---\ntitle: Improving the Trimmed Mean with Extreme Value Theory\ndate: '2022-12-08'\ncategories:\n  - Julia\n  - Experimentation\n  - Statistics\nimage: ../../_freeze/posts/trimmed_mean_extreme_value_theory/index/figure-html/fig-samples-output-1.svg\nbibliography: references.bib\ncap-location: margin\nabstract: 'Testing out some ideas for dealing with outliers in A/B testing, comparing the trimmed/windsorized means with a new estimator based on a combination of the pareto or generalised pareto distributions and the delta method.'\n---\n\n\n\n## A day in the life of an experimentation practitioner\n\nPicture the situation: you're a data scientist / statistician / economist at some e-commerce company. You're working with a team who need to test the impact of some new feature or promoption, and critically they want to evaluate the impact of the change on **revenue**. Sounds easy, so you get to work! \n\nYour randomisation and analysis units are visitors, and since the goal is to measure the impact on total revenue, your main metric is revenue per visitor. You will perform a t-test against the null hypothesis that the average revenue per visitor is the same in both control and treatment, and if you reject the null hypothesis you'll report the Average Treatment Effect (ATE), with a confidence interval, and pop the champaign!\n\nAs a responsible experimenter, you kick things off with a power analysis, to estimate the required sample size you'll need for this test. To do this you run a query to get the variance of the revenue per visitor over the last few weeks. And here, things start to go wrong... your variance is huge! At this rate, you'll have to run your test for months in order to measure any reasonable effect. \n\nSo now what? You plot a histogram of your revenue per visitor metric to see what's going on, and you see something like this:\n\n::: {.cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=3}\n![Hypothetical revenue per visitor histogram. Skewed, ;ots of zeros on one side. Massive outliers on the other side.](index_files/figure-html/fig-revenue-samples-output-1.svg){#fig-revenue-samples}\n:::\n:::\n\n\nAnd here's the problem. The distribution of the metric is highly skewed, with lots of zeros, then some \"normal\" spenders, and then a very small number of extreme spenders - we'll call these our outliers. And it's these outliers that are disproportionatly increasing the variance of your average revenue per visitor estimate, hurting your power, and eventually making you wait months to estimate the impact of your experiment. \n\n## Outliers in A/B testing\n\nThe previous section was a hypothetical story, but I think it's quite a common scenario. But what can be done? My usual steps are:\n\n1. First, check if they are real! It's often the case that outliers are actually just bad data. Before continuing, do some exploratory analysis to identify where these outliers are coming from and if they are real.\n1. Do some variance reduction! [CUPED](https://booking.ai/how-booking-com-increases-the-power-of-online-experiments-with-cuped-995d186fff1d) is a very effective method of reducing variance based on data from before the start of your experiment. It's always worth trying and it's about as close to a free lunch as you can get when it comes to improving A/B testing sensitivity. However, if your metric is skewed or has severe outliers, it's likely that CUPED won't solve that, and your power will still be limited by the outliers.\n1. If CUPED doesn't reduce your variance sufficiently, then it's time to look at trimming or windsorizing. These are very powerful techniques, but come with a significant drawback -> you are introducing bias into your estimates. \n\n::: {.callout-warning collapse=\"true\"}\n## Don't log transform!!\n\nOn almost every blog I see, when the issue of a skewed metric arises, someone will recommend to log-transform the metric. While this will certainly make your metric less skewed, and sometimes make sense, it's a big no-no for financial metrics like revenue. \n\nThis is because when you transform your metric, you also change the null hypothesis you are testing and therefore the interpretation of any effect you measure. For revenue, you really care about the effect on the **(arithmetic) mean** revenue per visitor, because improving this is what will translate into improving total revenue. However, the log transform means you are testing for an effect on the **geometric mean**, which is not the same and improving it does not necessarily translate into improving your bottom line, leading to potentially bad business decisions.\n:::\n\nTrimming and windsorizing are specifically designed to deal with outliers and make your estimator more robust. With trimming, you filter out all samples that are above some threshold, while with windsorizing you apply a cap, so that all values above a threshold are capped to that threshold. Both are very effective at reducing  variance, however they also introduce some bias, because you are biasedly removing or capping the top X data points, negatively biasing your estimates.\n\nBut is this the best we can do? In this post I'm going to explore how we might formalize this problem with Extreme Value Theory (EVT), and see if we can find some estimators that perform better than the trimmed or windsorized means. Here, by \"better\", I mean achieving similar levels of variance reduction, while introducing less bias.\n\n::: {.callout-tip}\nThis work was heavily inspired by the work by @psis on Pareto Smoothed Importance Sampling, which tackles the related problem of how to deal with extreme values in importance sampling.\n:::\n\n## Extreme Value Theory (EVT) and power laws\n\n::: {.callout-warning}\nDisclamer before I continue: I'm far from an expert in EVT, in this blog I'm basically parroting the things I've read when exploring EVT specifically for this problem of outliers. \n:::\n\nFirst, what is EVT? *EVT is a branch of statistics dealing with the extreme deviations from the median of probability distributions.*^[Sorry, this definition is fully plagarised from [Wikipedia](https://en.wikipedia.org/wiki/Extreme_value_theory#:~:text=Extreme%20value%20theory%20or%20extreme,extreme%20than%20any%20previously%20observed.), but it's good!] This is exactly what we are dealing with here - outliers are messing with our statistics. So perhaps there are some tools from EVT that we can use to reduce the bias in our trimmed / windsorized mean?\n\n### The pareto and generalised pareto distributions\n\nIn EVT the X theorem states that for a wide range of univariate probability distributions, the tail of that distribution can be well modelled by the Generalised Pareto Distribution (GPD). The GPD is a more flexible version of the well known Pareto distribution [@powerlaws]. \n\n::: {.callout-tip collapse=\"true\"}\n## GPD and Pareto Distributions\n\nThe probability density function of the Pareto distribution is given by:\n$$\nP_\\text{pareto}(x | \\alpha, \\theta) = \\frac{\\alpha \\theta^\\alpha}{x^{\\alpha-1}}\n$$\nThis distribution has two parameters, $\\alpha$ and $\\theta$:\n\n* $\\theta$ controls the minimum of the distribution: $x \\in [\\theta, \\infty)$\n* $\\alpha$ controls the slope of the distribution.\n\nThe probability density function of the GPD is given by:\n$$\nP_\\text{GPD}(x | \\mu, \\sigma, \\xi) = \\frac{1}{\\sigma} \\left( 1 + \\xi \\frac{x - \\mu}{\\sigma} \\right)^{-(1/\\xi + 1)}\n$$\n\nThe parameters of this distribution are more complex. In this post I'm going to only look at cases where $\\xi > 0$. In this case:\n\n* $\\mu$ controls the minimum of the distribution: $x \\in [\\mu, \\infty)$\n* $\\sigma$ controls the scale of the distribution. \n* $\\xi$ controls the slope of the power law tail of the distribution. Comparing it to $\\alpha$ for the Pareto distribution, $\\xi = 1 / \\alpha$.\n\nIn the case where $\\mu = \\sigma / \\xi$ the GPD is the same as the Pareto distributon.\n:::\n\nBoth the GPD and Pareto distribution are characterized by having \"power law\" tails, where for large X the distribution tends towards:\n\n$$\nP(x) \\rightarrow x^{-m} \\quad \\text{as} \\quad x \\rightarrow \\infty\n$$\n\nYou can see this in @fig-pareto below, where I compare the Pareto and GPD distribution with the LogNormal distribution, that does not have a power law tail:\n\n::: {.cell execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=4}\n![A comparison between the pareto distribution (red), the Generalised Pareto Distribution (GPD) (blue), and the log-normal distribution (green). Both axes are log scaled. Pareto has parameters alpha=1.5 and theta=20. GPD has parameters mu=100.0, theta=20.0 and xi=2/3. LogNormal has parameters mu=4.5, sigma=1.0.](index_files/figure-html/fig-pareto-output-1.svg){#fig-pareto}\n:::\n:::\n\n\nThe distributions are plotted on a log-log scale, and you can see that both the Pareto and GPD distributions are linear for large values of $x$ (indicating a power law), while the LogNormal distribution never becomes linear, it is always curving downwards.\n\nThe GPD and Pareto distribution differ at small values of $x$, where the GPD is more flexible and can curve up or down, while the Pareto distribution remains a pure power law for all values of $x$.\n\n### Infinite Variance\n\nWhen performing inference about the mean via the t-test, we typically use the first two moments: the sample mean and sample variance. If, for example, we are performing a one-sample t-test to test the null hypothesis that the mean of the population distribution is equal to a specific value $\\mu_0$, we would calculate the t-statistic as:\n\n$$\nt = \\frac{\\hat{\\mu} - \\mu_0}{\\hat{\\sigma} / \\sqrt{n}}\n$$\n\nWhere $\\hat{\\mu}$ is the sample mean, $\\hat{\\sigma}^2$ is the sample variance and $n$ is the sample size.\n\nDistributions with power law tails present a challenge here though, because depending on the slope of the tail, the population might have infinite mean or infinite variance. Specifically for the GPD and Pareto distributions we have the following three cases:\n\n|                                   | Pareto              | GPD                |\n|-----------------------------------|---------------------|--------------------|\n| 1. Infinite Mean and Variance     | $\\alpha \\leq 1$     | $\\xi \\geq 1$       |\n| 2. Finite Mean, Infinite Variance | $1 < \\alpha \\leq 2$ | $0.5 < \\xi \\leq 1$ |\n| 3. Finite Mean and Variance       | $\\alpha > 2$        | $\\xi \\leq 0.5$     |\n\n* If we are in case (1) where both the mean and variance are infinite, then there is basically no hope for any inference about the mean, since it's infinite! If you have a distribution with such large outliers that you are in this case, then you'll always struggle to perform any inference about it's mean.\n* If we are in case (3) then both the mean and variance are finite. This is trivial, and it's likely that the regular t-test based on the sample mean and variance will perform fine. This corresponds to the situation where there are no significant outliers in your metric.\n* Case (2) is the interesting one. The mean is finite, so we may want to perform inference on it, however the variance is infinite, which will break the t statisitc which uses the sample variance. **This will be the focus of rest of this post - how can we perform inference on the mean in cases like this?**\n\n**But what does infinte variance really mean?** The sample variance is always finite, even if the population distribution from which that sample was drawn has infinite variance. However, if the population distribution has infinite variance, then the sample variance will *not* converge as the sample size approaches infinty. \n\nThis can be seen in @fig-inf-variance below, where I simulate estimating the sample variance as a function of sample size for the Log-Normal and GPD distributions. Each grey line represents one sample, where I calculate the sample variance cumulatively, adding one point at a time. \n\n::: {.cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=5}\n![The sample variance vs sample size for the GPD (left) and Log-Normal distribution (right). The GPD used here has infinite population variance, so the sample variance does not converge as sample size increases.](index_files/figure-html/fig-inf-variance-output-1.png){#fig-inf-variance}\n:::\n:::\n\n\nYou can see that for the Log-Normal distribution, as the sample size gets large the variance converges towards the population variance, while for the GPD distribution it does not converge, and instead just keeps increasing. This is a problem, because we rely on the law of large numbers so that when we reach very large sample sizes, the sample statistics are a good approximation of the population statistics.\n\nSo if we cannot use the sample variance, what can we do? Well really we only use the sample variance so that we can estimated the standard error of the mean, $\\hat{\\sigma}_\\mu$, as:\n\n$$\n\\hat{\\sigma}_\\mu = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n$$\n\nIs there a way we can do this without the sample variance? Yes, with Maximum Likelihood Estimation and the delta method!\n\n## Inference about the mean of a power law distribution\n\nTo estimate the mean and the standard error on the mean via maximum likelihood estimation, we can follow these steps:\n\n1. Assume a parametric distribution for your population\n1. Fit your distribution to your data using maximum likelihood estimation\n1. Calculate the mean and the standard error of the mean from your maximum likelihood fit. This requires calculating the hessian, and using the delta method.\n\nThis method is nice because it doesn't require us to estimate the sample variance at any point, so we are able to estimate the mean and standard error on the mean, even when the population variance is infinite!\n\nIf you want to see the more detailed method, including all the nitty gritty maths, it's here:\n\n::: {.callout-tip collapse=\"true\"}\n## Detailed method with maths\n\n1. You have a sample of size $n$: $\\left[ X_1, X_2, X_3, ... X_n \\right]$\n1. Assume a parametric distribution for your population: $P(x|\\theta)$, where $\\theta$ is a vector of the parameters of the distribution.\n1. Define the Log Likelihood as: $L(\\theta) = \\sum_{j=1}^n \\ln{(P(X_j|\\theta))}$\n1. Estimate $\\hat{\\theta}$ by maximizing $L(\\theta)$: $\\hat{\\theta} = \\text{arg max}_{\\theta \\in \\Theta} L(\\theta)$\n1. Calculate the [hessian matrix](https://en.wikipedia.org/wiki/Hessian_matrix) of $L(\\theta)$, $H(\\theta)$. This is the matrix of second derivatives of $L$.\n1. Use the hessian matrix to estimate the covariance matrix for the standard errors of $\\hat{\\theta}$ as \n$\\hat{\\Sigma} = -H(\\hat{\\theta})^{-1}$, from [@covmle].\n1. Estimate the maximum likelihood estimate of the mean from $\\hat{\\theta}$, based on the parametric form for the mean of your chosen distribution $P(x|\\theta)$: $\\hat{\\mu} = E(\\hat{\\theta})$.\n1. Use the [delta method](https://en.wikipedia.org/wiki/Delta_method) to estimate the standard error on the mean, $\\hat{\\sigma}_\\mu$, where $\\Delta E(\\theta)$ is the first derivative (jacobian) of the mean function:\n\n$$\n\\hat{\\sigma}_\\mu^2 = \\Delta E(\\hat{\\theta})^T \\cdot \\hat{\\Sigma} \\cdot \\Delta E(\\hat{\\theta})\n$$ {#eq-delta-multivariate}\n\nNote: if the parameters are all independent, meaning the covariance matrix is a diagonal matrix, then the above equation simplifies to:\n\n$$\n\\hat{\\sigma}_\\mu^2 = \\sum_i \\left| \\frac{\\partial E}{\\partial \\theta_i} \\right|^2 \\hat{\\sigma}_i^2\n$$ {#eq-delta-indep}\n\nWhere $\\sigma_i^2$ are the diagonal elements of $\\hat{\\Sigma}$.\n:::\n\nThis method does have some drawbacks - you need to make an assumption about the parameteric form of the population distribution, and if that is incorrect it's very likely the estimator will be biased. Also, even if the parametric form is correctly specified, it's usually the case that the maximum likelihood estimator is not unbiased by default, it usually requires some bias correction to achieve that. I'm not going to do any bias correction in this post, but it would be interesting to explore!\n\nNow let's test this method using the GPD and Pareto distributions.\n\n### The Pareto (Hill) estimator\n\nThis method is simple for the Pareto distribution, as the maximum likelihood estimate can be calculated analytically, as is shown in [@paretoest]. This estimator is often known as the Hill estimator, and the parameters are calculated as:\n\n$$\n\\hat{\\theta} = \\min{(X_j)}\n$$\n$$\n\\hat{\\alpha} = \\frac{n}{\\sum_{j=1}^n \\ln{\\frac{X_j}{\\hat{\\theta}}}} = \\frac{n}{\\left( \\sum_{j=1}^n \\ln{X_j} \\right) - n \\ln{\\hat{\\theta}}}\n$$\n\nThe maximum likelihood estimator for the mean and standard error are then calculated from these parameters as:\n\n::: {.callout-tip collapse=\"true\"}\n## Derivation of the mean and standard error\n\nThe mean of the pareto distribution is given by:\n$$\n\\mu(\\theta, \\alpha) = \\frac{\\theta \\alpha}{\\alpha - 1}\n$$\n\nThe parameters are independent, so there is no covariance. Their standard errors are given by REFERENCE WIKIPEDIA:\n\n$$\n\\hat{\\sigma}_\\alpha = \\frac{\\hat{\\alpha}}{\\sqrt{n}}\n$$\n\n$$\n\\hat{\\sigma}_\\theta = ...\n$$\n\nWe can calculate the standard error on the mean using @eq-delta-indep:\n\n$$\n\\hat{\\sigma}_\\mu^2 = \\left| \\frac{\\partial \\mu}{\\partial \\alpha} \\right|^2 \\hat{\\sigma}_\\alpha^2 + \\left| \\frac{\\partial \\mu}{\\partial \\theta} \\right|^2 \\hat{\\sigma}_\\theta^2\n$$\n\nCalculating the derivatives and substituting them in, we get the following equation for the standard error on the mean:\n\n$$\n\\hat{\\sigma}_\\mu = \\frac{\\theta}{\\sqrt{n}} \\frac{\\alpha^2 - \\alpha + 1}{(\\alpha - 1)^2}\n$$\n:::\n\n$$\n\\hat{\\mu}_\\text{pareto} = \\frac{\\hat{\\theta} \\hat{\\alpha}}{\\hat{\\alpha} - 1}\n$$\n$$\n\\hat{\\sigma}_{\\mu, \\text{ pareto}} = \\frac{\\hat{\\theta}}{\\sqrt{n}} \\frac{\\hat{\\alpha}^2 - \\hat{\\alpha} + 1}{(\\hat{\\alpha} - 1)^2}\n$$\n\nThis is implemented in Julia below:\n\n\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nfunction hill_estimator(x::Vector{Float64})\n\tn = length(x)\n\n\t# Maximum likelihood estimates of the pareto parameters\n\tθ = minimum(x)\n\tα = n / (sum(log.(x)) - n * log(θ))\n\n\tif α <= 1.0\n\t\t# If alpha is less than 1, the mean is infinite. \n\t\t# In this case this estimator won't work, so fall\n\t\t# back to the sample mean and variance.\n\t\treturn sample_mean_variance_estimator(x)\n\tend\n\n\t# Estimate the mean and standard error from the MLE parameters\n\tμ = α * θ / (α - 1)\n\tσ = abs(μ) * sqrt(1.0 / ((α - 1)^2 * n) + (α - 1)^2 / (α^2 * n))  \n\t# CHECK THIS DERIVATION PROPERLY\n\n\t# Return a struct holding the estimated mean and standard error\n\treturn EstimatorResult(μ, σ) \nend\n```\n:::\n\n\n### The GPD estimator\n\nFor the GPD estimator it's more complicated, because there is no closed form solution to the maximum likelihood estimation. This is a well known challenge in EVT and many methods have been proposed to fit the GPD to a sample. \n\nHere I will be using the method proposed by @zhang_gpdfit, which was already implemented in the `ParetoSmooth.jl` package. I will then use the great automatic differentiation built into Julia in `ForwardDiff.jl` to estimate the gradient and hessian, which I use to estimate the standard error on the mean via @eq-delta-multivariate. \n\nThe full implementation in Julia is here:\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nusing ParetoSmooth: gpd_fit\nusing ForwardDiff: gradient, hessian\n\nfunction gpd_log_pdf(params::AbstractVector, x::Vector{Float64})\n\tsum(logpdf.(GeneralizedPareto(params...), x))\nend\n\nfunction gpd_mean(params::AbstractVector)\n\tmean(GeneralizedPareto(params...))\nend\n\nfunction gpd_estimator(x::Vector{Float64})\n\tn = length(x)\n\n\t# Estimate the GPD parameters numerically\n\tu = minimum(x)\n\tx_centered = x .- u\n\tξ, σ = gpd_fit(x_centered, 1.0; sort_sample=true, wip=false)\n\tparams = [u, σ, ξ]\n\n\tif ξ >= 1.0\n\t\t# If xi is greater than 1, the mean is infinite. \n\t\t# In this case this estimator won't work, so fall\n\t\t# back to the sample mean and variance.\n\t\treturn sample_mean_variance_estimator(x)\n\tend\n\n\t# Perform the automatic differentiation to get the \n\t# required gradient and hessian\n\tH = hessian(z -> gpd_log_pdf(z, x), params)\n\tΣ = (-1 * H) ^ -1\n\tdμ = gradient(gpd_mean, params)\n\n\t# Estimate the mean and the standard error\n\tμ = gpd_mean(params)\n\tv = transpose(dμ) * Σ * dμ\n\n\t# Return a struct holding the estimated mean and standard error\n\treturn EstimatorResult(μ, sqrt(v))\nend\n```\n:::\n\n\n### How do these estimators perform?\n\n\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=10}\n![Distribution of estimates for a Pareto population distribution, with alpha=1.5 and theta=20.](index_files/figure-html/fig-evt-estimator-comparison-pareto-output-1.svg){#fig-evt-estimator-comparison-pareto}\n:::\n:::\n\n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=11}\n![Distribution of estimates for a GPD population distribution, with mu=100, theta=20.0, xi=2/3.](index_files/figure-html/fig-evt-estimator-comparison-gpd-output-1.svg){#fig-evt-estimator-comparison-gpd}\n:::\n:::\n\n\n::: {.cell execution_count=11}\n\n::: {.cell-output .cell-output-display execution_count=12}\n![Average performance of estimators for a Pareto population distribution, with alpha=1.5 and theta=20. RMSE is the Root Mean Squared Error of the estimates vs the true population mean, the Standard Deviation is the standard deviation of the estimates, and the |Bias| is the absolute value of the difference between the average of the estimates and the true population mean. Ideally we want |Bias|=0 and then RMSE and Standard Deviaton as small as possible.](index_files/figure-html/fig-evt-estimator-stats-comparison-pareto-output-1.svg){#fig-evt-estimator-stats-comparison-pareto}\n:::\n:::\n\n\n::: {.cell execution_count=12}\n\n::: {.cell-output .cell-output-display execution_count=13}\n![Average performance of estimators for a GPD population distribution, with mu=100, theta=20.0, xi=2/3. RMSE is the Root Mean Squared Error of the estimates vs the true population mean, the Standard Deviation is the standard deviation of the estimates, and the |Bias| is the absolute value of the difference between the average of the estimates and the true population mean. Ideally we want |Bias|=0 and then RMSE and Standard Deviaton as small as possible.](index_files/figure-html/fig-evt-estimator-stats-comparison-gpd-output-1.svg){#fig-evt-estimator-stats-comparison-gpd}\n:::\n:::\n\n\n::: {.cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=14}\n![A comparison of the standardised errors of the different estimators for a Pareto population distribution, where the standardised error is the difference between the estimated mean and the population mean, divided by the estimated standard deviation. The t-test assumes that this statistic is approximately t-distributied, with d.o.f = samples size - 1. This expected distribution is shown in red. If the distribution matches, then you can expect the confidence intervals you calculate to have good coverage.](index_files/figure-html/fig-evt-estimator-normed-comparison-pareto-output-1.svg){#fig-evt-estimator-normed-comparison-pareto}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=15}\n![A comparison of the standardised errors of the different estimators for a GPD population distribution, where the standardised error is the difference between the estimated mean and the population mean, divided by the estimated standard deviation. The t-test assumes that this statistic is approximately t-distributied, with d.o.f = samples size - 1. This expected distribution is shown in red. If the distribution matches, then you can expect the confidence intervals you calculate to have good coverage.](index_files/figure-html/fig-evt-estimator-normed-comparison-gpd-output-1.svg){#fig-evt-estimator-normed-comparison-gpd}\n:::\n:::\n\n\n## Appling EVT to the trimmed mean\n\nIn the previous section I was only really looking at how we can \n\n* We can formalise this by assuming that the majority of our sample comes from some well behaved population distribution, but a small number of samples are drawn from a population distribution with infinite variance. For example, the Pareto distribution [@powerlaws].\n* This contribution from the infinite variance distribution is a problem, because it causes the mixture distribution to also have infinite variance, and therefore the central limit theorem breaks down. \n\n## Summary\n\nTODO:\n* Compare trimming, winzoring and pareto smoothing with different cutoffs\n* Use KDE + Pareto mixture. Then take the mean of the MLE pareto + mean of other data for estimator. Use laplace approx for variance.\n* Basic check: is Hill better at estimating mean than sample mean?\n\nSECTIONS:\n1. Introduction on A/B testing, revenue as a metric, and outliers. Talk about outliers as coming from a distribution with infinite population variance.\n2. Infinite population variance: the Pareto distribution. What does infinite variance mean? Why is it a problem for A/B testing? Do a simulation with a simple welches t-test.\n3. What can we not do? Log transform, median test, non-parametric test. We care about the mean. \n4. Simple solutions: trimming vs windsorizing. These are a bias variance tradeoff. How do they perform? Do the same simulations.\n5. What if we model the tail as a pareto distribution directly? Try PSIS and a KDE + Pareto Mixture for MLE. \n6. Choosing the best cutoff? KS test, AIC, BIC, Mixture? Mixture doesn't need a cutoff - that's nice. \n7. Final comparison and results. My recommendation. Key points - choose the cutoff without looking at the results to avoid peaking.  \n\nMethod:\n\nThe following is inspired by the Pareto Smoothed Importance Sampling paper [@psis]:\n\n1. Set $M = min(0.2 S, 3 \\sqrt{S})$ OR find best M using KS-test [@powerlawsempirical];\n2. Set $\\hat{u} = x_{S-M}$\n3. Estimate $\\alpha$ of the tail, using the standard Hill estimator\n4. Set $x'_{S-M+z} = \\min{ \\left( F^{-1} \\left( \\frac{z - 1/2}{M} \\right), \\max_s{(x_s)} \\right)}$\n\nNow perform a t-test on $x'$ instead of $x$. \n\nThroughout this article we will use two types of distributions to represent distributions with infinite variance, the Pareto distribution and the Generalised Pareto Distribution (GPD). \n\n\n\nBoth of these distributions have a power law tail, and therefore can have infinite variance. This is noticable when plotted on a log-log scale (as is shown in @fig-pareto), where the tail will be linear. This is shown in contrast to a Log-Normal distribution, where the tail is not Linear, and eventually at very high $X$ the PDF drops below the power law tails. \n\nWhile the two types of pareto distribution have the same tail behavior, they differ in how they behave at small values of $X$. The Pareto distribution is a pure power law until some value, below which the probability mass is 0, while the Generalised Pareto Distribution smoothly transitions away from being power law at low X. The GPD is a more general distribution - with the correct parameters in the GPD you can get back to the Pareto distribution - however it can be harder to fit to data because it has more parameters. \n\nThe challenge for A/B testing can be demonstrated by comparing these distributions with the log-normal distribution. While you are always able to calculate the sample variance of any sample of data, whether it is from a population with finite or infinite variance, if the sample is drawn from a population with infinite variance then the sample variance will not converge as the sample size increases. You can see this in the example below, where I sample from a GPD and a LogNormal Distribution and then calculate the sample variance vs sample size. \n\n\n\nThis causes problems for the t-test, since it uses the sample variance to estimate the standard error on the mean. So if your data has a power law tail, it's unlikely that this will give a good estimate. \n\nPower law tails are usualy quantified using the Hill Estimator. We can get the standard error on that estimate too. Let's compare the Hill estimator + Delta method with the mean and variance estimator for the regular Pareto distribution.\n\n\n\nYou can see that the hill estimator performs much better than using the same mean and variance. \n\nSo we want to use the Hill estimator instead of the sample mean and variance, but **only in the tail**. The rest of the distribution is unlikely to be pareto distributed, so the Hill estimator would fail there. This brings us to the next challenge: how do we decide when we are \"in the tail\"?\n\nTo do this, we will use a semi-parametric mixture of the Pareto distribution in the tail and a Kernel Density Approximation (KDE) elsewhere. The KDE bandwidth and cutoff threshold for the tail will be chosen by maximizing the Leave-One-Out (LOO) likelihood.\n\nTo test this out, I'll create a synthetic dataset which is a mixture of a GPD and two lognormal distributions. This will make the main distribution bimodal (and so not too easy for our method) but with a power law tail that gives it infinite variance. This distribution is shown in @fig-samples. \n\n::: {.cell execution_count=15}\n\n::: {.cell-output .cell-output-display execution_count=16}\n![Histogram of samples from simulated data (blue), and the theoretical PDF (orange).](index_files/figure-html/fig-samples-output-1.svg){#fig-samples}\n:::\n:::\n\n\n\n\n::: {.cell execution_count=17}\n\n::: {.cell-output .cell-output-display execution_count=18}\n![Performance of the different trimming methods based on various metrics. The RMSE and Standard Deviation should be as small as possible. The Bias should be as close to 0.0 as possible, the Standardised RMSE should be 1.0 and the 95% coverage should be 0.95. The last 3 target values are marked by black horizontal lines.](index_files/figure-html/fig-trimming-sim-by-metric-output-1.svg){#fig-trimming-sim-by-metric}\n:::\n:::\n\n\n::: {.cell execution_count=18}\n\n::: {.cell-output .cell-output-display execution_count=19}\n![How the different components (Bias and Standard Deviation) contribute towards the overall RMSE of the estimators.](index_files/figure-html/fig-trimming-sim-by-method-output-1.svg){#fig-trimming-sim-by-method}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}