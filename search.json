[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there! I’m Sam Bailey, and I’m a Principal Data Scientist at Booking.com. My day job involves a lot of python, statistics, and randomised controlled trials.\nBut in my free time, I like to explore new topics that catch my interest. That usually involves writing some python or julia, whether it’s coding something from scratch or just testing out a new library.\nAt the end of the day, I try to put my thoughts into words and share them on this blog. I hope you find my musings interesting and maybe even useful! Thanks for stopping by.\nThis text was edited by ChatGPT, with the prompt “Make this sound like a light hearted, ‘about me’ section of a blog”."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Python Code",
    "section": "",
    "text": "This is a post with executable code. Let’s try some python."
  },
  {
    "objectID": "posts/post-with-code/index.html#subheading",
    "href": "posts/post-with-code/index.html#subheading",
    "title": "Post With Python Code",
    "section": "Subheading",
    "text": "Subheading\nMore stuff"
  },
  {
    "objectID": "posts/outliers-for-ab-testing/index.html",
    "href": "posts/outliers-for-ab-testing/index.html",
    "title": "Trimming Outliers for A/B Testing",
    "section": "",
    "text": "Running A/B tests targeting continuous metrics like revenue per visitor are important for companies to evaluate the financial impact of their interventions\nThese metrics are often hard from a statistical perspective because they are influenced by outliers, which dramatically hurt experimental power\nOne way to think about these outliers is to say you don’t want to optimize your website for a minority of extremely high value customers, since this is high risk. This thinking goes towards the ideas of quantitative finance, and I won’t explore this in this post.\nAnother reason could be data issues. Lets assume we rule that out.\nThe second way is to say you want to optimize your website for everyone, so you can’t ignore the outliers, but their existance makes standard statistical tests inefficient, so we try to find more efficient estimators that require introducing as little bias as possible.\nWe can formalise this by assuming that the majority of our sample comes from some well behaved population distribution, but a small number of samples are drawn from a population distribution with infinite variance. For example, the Pareto distribution (Newman 2005).\nThis contribution from the infinite variance distribution is a problem, because it causes the mixture distribution to also have infinite variance, and therefore the central limit theorem breaks down.\nTODO: * Compare trimming, winzoring and pareto smoothing with different cutoffs * Use KDE + Pareto mixture. Then take the mean of the MLE pareto + mean of other data for estimator. Use laplace approx for variance. * Basic check: is Hill better at estimating mean than sample mean?\nSECTIONS: 1. Introduction on A/B testing, revenue as a metric, and outliers. Talk about outliers as coming from a distribution with infinite population variance. 2. Infinite population variance: the Pareto distribution. What does infinite variance mean? Why is it a problem for A/B testing? Do a simulation with a simple welches t-test. 3. What can we not do? Log transform, median test, non-parametric test. We care about the mean. 4. Simple solutions: trimming vs windsorizing. These are a bias variance tradeoff. How do they perform? Do the same simulations. 5. What if we model the tail as a pareto distribution directly? Try PSIS and a KDE + Pareto Mixture for MLE. 6. Choosing the best cutoff? KS test, AIC, BIC, Mixture? Mixture doesn’t need a cutoff - that’s nice. 7. Final comparison and results. My recommendation. Key points - choose the cutoff without looking at the results to avoid peaking.\nMethod:\nThe following is inspired by the Pareto Smoothed Importance Sampling paper (Vehtari et al. 2015):\nNow perform a t-test on \\(x'\\) instead of \\(x\\).\nHill estimator:\n\\[\n\\alpha = 1 + n \\left[\\sum_{i=1}^n \\ln{ \\frac{x_i}{x_\\text{min}} } \\right]^{-1}\n\\]\nThroughout this article we will use two types of distributions to represent distributions with infinite variance, the Pareto distribution and the Generalised Pareto Distribution (GPD).\nBoth of these distributions have a power law tail, and therefore can have infinite variance. This is noticable when plotted on a log-log scale (as is shown in Figure 1), where the tail will be linear. This is shown in contrast to a Log-Normal distribution, where the tail is not Linear, and eventually at very high \\(X\\) the PDF drops below the power law tails.\nWhile the two types of pareto distribution have the same tail behavior, they differ in how they behave at small values of \\(X\\). The Pareto distribution is a pure power law until some value, below which the probability mass is 0, while the Generalised Pareto Distribution smoothly transitions away from being power law at low X. The GPD is a more general distribution - with the correct parameters in the GPD you can get back to the Pareto distribution - however it can be harder to fit to data because it has more parameters.\nThe challenge for A/B testing can be demonstrated by comparing these distributions with the log-normal distribution. While you are always able to calculate the sample variance of any sample of data, whether it is from a population with finite or infinite variance, if the sample is drawn from a population with infinite variance then the sample variance will not converge as the sample size increases. You can see this in the example below, where I sample from a GPD and a LogNormal Distribution and then calculate the sample variance vs sample size.\nThis causes problems for the t-test, since it uses the sample variance to estimate the standard error on the mean. So if your data has a power law tail, it’s unlikely that this will give a good estimate.\nPower law tails are usualy quantified using the Hill Estimator. We can get the standard error on that estimate too. Let’s compare the Hill estimator + Delta method with the mean and variance estimator for the regular Pareto distribution.\nYou can see that the hill estimator performs much better than using the same mean and variance.\nSo we want to use the Hill estimator instead of the sample mean and variance, but only in the tail. The rest of the distribution is unlikely to be pareto distributed, so the Hill estimator would fail there. This brings us to the next challenge: how do we decide when we are “in the tail”?\nTo do this, we will use a semi-parametric mixture of the Pareto distribution in the tail and a Kernel Density Approximation (KDE) elsewhere. The KDE bandwidth and cutoff threshold for the tail will be chosen by maximizing the Leave-One-Out (LOO) likelihood.\nTo test this out, I’ll create a synthetic dataset which is a mixture of a GPD and two lognormal distributions. This will make the main distribution bimodal (and so not too easy for our method) but with a power law tail that gives it infinite variance. This distribution is shown in Figure 4.\nNow I can build my method to estimate the mean of that distribution, and the standard error on the mean.\nNow lets investigate the tail of this distribution. Does it look like a power law? Can we fit one to it?\nITS CLOSE BUT I MUST HAVE SLIGHTLY THE WRONG FORMULAS\nNow I will implement my method\nNow test it systematically"
  },
  {
    "objectID": "posts/outliers-for-ab-testing/index.html#generate-toy-dataset",
    "href": "posts/outliers-for-ab-testing/index.html#generate-toy-dataset",
    "title": "Trimming Outliers for A/B Testing",
    "section": "Generate toy dataset",
    "text": "Generate toy dataset\nTo test these methods, I need some synthetic data. I’ll generate a mixture of a log-normal distribution and a Pareto distribution. The lognormal represents most users, but the Pareto represents the outliers. The pareto is especially problematic for statistics, since it has infinite variance, meaning the CLT won’t work."
  },
  {
    "objectID": "posts/outliers-for-ab-testing/index.html#outlier-detection",
    "href": "posts/outliers-for-ab-testing/index.html#outlier-detection",
    "title": "Trimming Outliers for A/B Testing",
    "section": "Outlier Detection",
    "text": "Outlier Detection\nNow we want to try to identify the outliers that came from the pareto distributon. I’ll try to do this by modelling the data as:\n\nA KDE density estimation. This is for the bulk data, and is non-parametric so it should work on any dataset. I need to choose a kernel, for this data I’ll choose lognormal.\nA generalized pareto distribution. This should model the outliers."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Expand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Post With Python Code\n\n\n0 min\n\n\n\nPython\n\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimming Outliers for A/B Testing\n\n\n15 min\n\n\n\nJulia\n\n\n\n\n\n\n\nDec 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n0 min\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  }
]